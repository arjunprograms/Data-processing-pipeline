# Data-processing-pipeline

This repository provides a modular and flexible Data Processing Pipeline for handling structured datasets. It includes a variety of machine learning and data processing techniques such as feature selection, clustering, dimensionality reduction, and anomaly detection, with an emphasis on reusability and customization.

Features
Feature Selection: Extracts important features using methods like Random Forest.
Clustering: Implements K-Means (with Elbow Method optimization) and HDBSCAN for unsupervised learning tasks.
Dimensionality Reduction: Performs PCA and t-SNE for reducing data complexity.
Anomaly Detection: Detects outliers using Local Outlier Factor (LOF).
Visualization: Creates 2D and 3D plots, including labeled data visualization.
Automation: Modular blocks with multiprocessing support for streamlined processing.
